{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Product Catergorisation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The correct categorisation of products is a very important step for online \n",
    "shops. This step might look straightforward, but it can easily be a nightmare. \n",
    "This could be due to any number of difficulties, including: 1) the number of \n",
    "available categories can be huge, 2) the number of available categories can \n",
    "change constantly, and 3) new products may be added daily.\n",
    "\n",
    "Manual categorisation of products can be a tedious and labour-intensive task.\n",
    "Therefore, it makes sense to automate this process. One method is to use \n",
    "machine learning.\n",
    "\n",
    "In this task, I will implement a product categoriser based on the following \n",
    "explanation.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Approach Description"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As shown in the table below, there are three levels of categories. Level 1 is \n",
    "the highest and most generic and level 3 is the most specific. The idea is to \n",
    "create multiple models over a number of iterations. \n",
    "In the first pass we create one model using the features and the Level 1 \n",
    "column as the class variable. \n",
    "In the next pass (to predict level 2), we create one separate model for each \n",
    "unique category in Level 1.\n",
    "Similarly, for Level 3, the number of models we create is the same as the \n",
    "number of distinct groups of combinations of the categories in Level 1 and \n",
    "Level "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"Product_categorisation.png\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The total number of models we need to create depends on the number of \n",
    "categories. For example, if the number of unique categories was 12, 22 and \n",
    "31 in Levels 1, 2 and 3 respectively, then the total number of models created \n",
    "will be one model in the first pass, 12 models in the second pass and 264 (12 \n",
    "\\* 22) models in the third pass. This makes the total number of models 277 (in \n",
    "a mock run of a model solution to this task, the number of models was \n",
    "between 50 and 60)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load and explore the data (4 marks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Description</th>\n",
       "      <th>Level_1</th>\n",
       "      <th>Level_2</th>\n",
       "      <th>Level_3</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>gerb cap help keep littl on head cov warm day ...</td>\n",
       "      <td>09BF5150</td>\n",
       "      <td>C7E19</td>\n",
       "      <td>D06E</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>newborn inf toddl boy hoody jacket oshkosh b g...</td>\n",
       "      <td>2CEC27F1</td>\n",
       "      <td>ADAD6</td>\n",
       "      <td>98CF</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>tut ballet anym leap foxy fash ruffl tul toddl...</td>\n",
       "      <td>09BF5150</td>\n",
       "      <td>C7E19</td>\n",
       "      <td>D06E</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>newborn inf toddl boy hoody jacket oshkosh b g...</td>\n",
       "      <td>2CEC27F1</td>\n",
       "      <td>ADAD6</td>\n",
       "      <td>98CF</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>easy keep feel warm cozy inf toddl girl hoody ...</td>\n",
       "      <td>2CEC27F1</td>\n",
       "      <td>ADAD6</td>\n",
       "      <td>98CF</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                         Description   Level_1 Level_2 Level_3\n",
       "0  gerb cap help keep littl on head cov warm day ...  09BF5150   C7E19    D06E\n",
       "1  newborn inf toddl boy hoody jacket oshkosh b g...  2CEC27F1   ADAD6    98CF\n",
       "2  tut ballet anym leap foxy fash ruffl tul toddl...  09BF5150   C7E19    D06E\n",
       "3  newborn inf toddl boy hoody jacket oshkosh b g...  2CEC27F1   ADAD6    98CF\n",
       "4  easy keep feel warm cozy inf toddl girl hoody ...  2CEC27F1   ADAD6    98CF"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#import the data\n",
    "df=pd.read_csv(\"./product-cat-dataset.csv\")\n",
    "#printing first 5 row of our dataset\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10649, 4)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#checking the amout of rows and columns\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 10649 entries, 0 to 10648\n",
      "Data columns (total 4 columns):\n",
      " #   Column       Non-Null Count  Dtype \n",
      "---  ------       --------------  ----- \n",
      " 0   Description  10637 non-null  object\n",
      " 1   Level_1      10649 non-null  object\n",
      " 2   Level_2      10649 non-null  object\n",
      " 3   Level_3      10649 non-null  object\n",
      "dtypes: object(4)\n",
      "memory usage: 332.9+ KB\n"
     ]
    }
   ],
   "source": [
    "#checking if there are any null entries\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As we can see the amount of non-null for column Description is not equal to the amount of other columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Description</th>\n",
       "      <th>Level_1</th>\n",
       "      <th>Level_2</th>\n",
       "      <th>Level_3</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>10637</td>\n",
       "      <td>10649</td>\n",
       "      <td>10649</td>\n",
       "      <td>10649</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>unique</th>\n",
       "      <td>9677</td>\n",
       "      <td>15</td>\n",
       "      <td>39</td>\n",
       "      <td>43</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>top</th>\n",
       "      <td>glory gorg col fing complet outfit express moo...</td>\n",
       "      <td>B092BA29</td>\n",
       "      <td>2D5A3</td>\n",
       "      <td>28A7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>freq</th>\n",
       "      <td>24</td>\n",
       "      <td>900</td>\n",
       "      <td>797</td>\n",
       "      <td>797</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              Description   Level_1 Level_2  \\\n",
       "count                                               10637     10649   10649   \n",
       "unique                                               9677        15      39   \n",
       "top     glory gorg col fing complet outfit express moo...  B092BA29   2D5A3   \n",
       "freq                                                   24       900     797   \n",
       "\n",
       "       Level_3  \n",
       "count    10649  \n",
       "unique      43  \n",
       "top       28A7  \n",
       "freq       797  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#describing data and checking unique values\n",
    "df.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Level_1 has 15 unique values, Level_2 39 and Level_3 43"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Deal with Missing Data (4 marks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Description    12\n",
       "Level_1         0\n",
       "Level_2         0\n",
       "Level_3         0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Checking null entries count in Description column\n",
    "missing_values_count=df.isnull().sum()\n",
    "missing_values_count"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Description has a total of 12 missing values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Percentage of values missing is in Description column is: 0.03%\n"
     ]
    }
   ],
   "source": [
    "#Checking percentage of missing values\n",
    "total_cells=np.product(df.shape)\n",
    "total_missing=missing_values_count.sum()\n",
    "\n",
    "percent_missing=(total_missing/total_cells)*100\n",
    "print(f\"Percentage of values missing is in Description column is: {round(percent_missing,2)}%\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Most probably this entries are missing because they were not recorded rather than because they don't exist. The amout of data missing is negligible we can drop those missing values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rows in original dataset: 10649\n",
      "\n",
      "Rows with na's dropped: 10637 \n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Dropping missing rows\n",
    "df_new=df.dropna()\n",
    "print(f\"Rows in original dataset: {df.shape[0]}\\n\")\n",
    "print(f\"Rows with na's dropped: {df_new.shape[0]} \\n\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Drop Classes where the number of instances is < 10 (4 marks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "the number of classes with instances <10 is : 0\n"
     ]
    }
   ],
   "source": [
    "# Apply to Level_1 \n",
    "n_instances_l1=(df_new[\"Level_1\"].value_counts(ascending=True)<10).sum()\n",
    "print(f\"the number of classes with instances <10 is : {n_instances_l1}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "the number of classes with instances <10 is : 3\n"
     ]
    }
   ],
   "source": [
    "# Apply to Level_2\n",
    "n_instances_l2=(df_new[\"Level_2\"].value_counts(ascending=True)<10).sum()\n",
    "print(f\"the number of classes with instances <10 is : {n_instances_l2}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "shape before (10637, 4)\n",
      "shape after drop (10629, 4)\n"
     ]
    }
   ],
   "source": [
    "print(f\"shape before {df_new.shape}\")\n",
    "df_new=df_new[df_new.groupby('Level_2')[\"Level_2\"].transform('count')>=10]\n",
    "print(f\"shape after drop {df_new.shape}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "the number of classes with instances <10 is : 2\n"
     ]
    }
   ],
   "source": [
    "# Apply to Level_3\n",
    "n_instances_l3=(df_new[\"Level_3\"].value_counts(ascending=True)<10).sum()\n",
    "print(f\"the number of classes with instances <10 is : {n_instances_l3}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "shape before (10629, 4)\n",
      "shape after drop (10627, 4)\n"
     ]
    }
   ],
   "source": [
    "print(f\"shape before {df_new.shape}\")\n",
    "df_new=df_new[df_new.groupby('Level_3')[\"Level_3\"].transform('count')>=10]\n",
    "print(f\"shape after drop {df_new.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Now let's write a Function to Prepare Text (4 marks)\n",
    "We will apply it to our DataFrame later on\n",
    "\n",
    "* This function receives a text string and performs the following:\n",
    "* Convert text to lower case\n",
    "* Remove punctuation marks\n",
    "* Apply stemming using the popular Snowball or Porter Stemmer (optional)\n",
    "* Apply NGram Tokenisation\n",
    "* Return the tokenised text as a list of strings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to C:\\Users\\Massimiliano\n",
      "[nltk_data]     Gargano\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nltk\n",
    "nltk.download(\"punkt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "#importing libraries\n",
    "from nltk.stem.snowball import SnowballStemmer\n",
    "from nltk.stem import PorterStemmer\n",
    "from nltk import word_tokenize, ngrams\n",
    "import string\n",
    "\n",
    "def process_text(text, n = 1):\n",
    "    \"\"\"\n",
    "    Takes in a string of text, then performs the following:\n",
    "    1. Convert text to lower case and remove all punctuation\n",
    "    2. Optionally apply stemming\n",
    "    3. Apply Ngram Tokenisation\n",
    "    4. Returns the tokenised text as a list\n",
    "    \"\"\"\n",
    "    #1\n",
    "    text=text.lower()\n",
    "    text=text.translate(str.maketrans('', '', string.punctuation))\n",
    "\n",
    "    #2\n",
    "    en = SnowballStemmer('english')\n",
    "    text=en.stem(text)\n",
    "\n",
    "    #3\n",
    "    text = list(ngrams(text.split(), n))\n",
    "    tokenised=[\" \".join(i) for i in text]\n",
    "\n",
    "            \n",
    "    return tokenised"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['here were testing',\n",
       " 'were testing the',\n",
       " 'testing the processtext',\n",
       " 'the processtext function',\n",
       " 'processtext function results',\n",
       " 'function results are',\n",
       " 'results are as',\n",
       " 'are as follow']"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Here is an example function call\n",
    "process_text(\"Here we're testing the process_text function, results are as follows:\", n = 3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Now let's apply TF-IDF to extract features from plain text (10 marks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Here you apply the process_text function to the Description column of the data\n",
    "# Then you pass the results to the bag of words tranformer\n",
    "\n",
    "#Let's create the corpus \n",
    "\n",
    "#corpus=df_new.Description.tolist()\n",
    "\n",
    "corpus=[process_text(i) for i in df_new.Description]\n",
    "corpus\n",
    "\n",
    "corpus=[\" \".join(subset) for subset in corpus]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "CountVectorizer()"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "#initiate CountVectorizer()\n",
    "vectorizer=CountVectorizer()\n",
    "vectorizer\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10627, 16635)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#let's generate the word counts matrix\n",
    "X=vectorizer.fit_transform(corpus)\n",
    "X.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we can use .transform on our Bag-of-Words (bow) transformed object and transform the entire DataFrame of text file contents. Let's go ahead and check out how the bag-of-words counts for the entire corpus in a large, sparse matrix:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TfidfTransformer()"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# After that you pass the result of the previous step to sklearn's TfidfTransformer\n",
    "# which will convert them into a feature matrix\n",
    "# See here: https://scikit-learn.org/stable/modules/generated/sklearn.feature_extraction.text.TfidfTransformer.html\n",
    "from sklearn.feature_extraction.text import TfidfTransformer\n",
    "#initiate TfidfTransformer()\n",
    "transformer = TfidfTransformer()\n",
    "transformer\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<10627x16635 sparse matrix of type '<class 'numpy.float64'>'\n",
       "\twith 298015 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tfidf = transformer.fit_transform(X)\n",
    "tfidf\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>16625</th>\n",
       "      <th>16626</th>\n",
       "      <th>16627</th>\n",
       "      <th>16628</th>\n",
       "      <th>16629</th>\n",
       "      <th>16630</th>\n",
       "      <th>16631</th>\n",
       "      <th>16632</th>\n",
       "      <th>16633</th>\n",
       "      <th>16634</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 16635 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   0      1      2      3      4      5      6      7      8      9      ...  \\\n",
       "0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0  ...   \n",
       "1    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0  ...   \n",
       "2    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0  ...   \n",
       "3    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0  ...   \n",
       "4    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0  ...   \n",
       "\n",
       "   16625  16626  16627  16628  16629  16630  16631  16632  16633  16634  \n",
       "0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0  \n",
       "1    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0  \n",
       "2    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0  \n",
       "3    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0  \n",
       "4    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0  \n",
       "\n",
       "[5 rows x 16635 columns]"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# The resulting matrix is in sparse format, we can transform it into dense\n",
    "# Code prepared for you so you can see what results look like\n",
    "text_tfidf = pd.DataFrame(tfidf.toarray())\n",
    "text_tfidf.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Now the Data is Ready for Classifier Usage"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Split Data into Train and Test sets (4 marks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train/Test split\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "#target\n",
    "classes=[\"Level_1\",\"Level_2\",\"Level_3\"]\n",
    "y=df_new[classes]\n",
    "\n",
    "#features\n",
    "X=text_tfidf\n",
    "\n",
    "train_X, test_X, train_y, test_y = train_test_split(X, y, random_state=1, )\n",
    "\n",
    "tree=DecisionTreeClassifier(random_state=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# You might need to reset index in each dataframe (depends on you how you do things)\n",
    "# done for you to make it clearer\n",
    "train_X.reset_index(inplace=True, drop=True)\n",
    "test_X.reset_index(inplace=True, drop=True)\n",
    "train_y.reset_index(inplace=True, drop=True)\n",
    "test_y.reset_index(inplace=True, drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# You might need to take classes as separate columns (depends on you how you do things)\n",
    "class1 = train_y['Level_1'].astype(str)\n",
    "class2 = train_y['Level_2'].astype(str)\n",
    "class3 = train_y['Level_3'].astype(str)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model training for the three levels (8 marks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create and save model for level 1\n",
    "import pickle\n",
    "#Fit the model\n",
    "tree.fit(train_X, class1)\n",
    "\n",
    "#save model for level 1\n",
    "with open('level1.pk', 'wb') as cls:\n",
    "    pickle.dump(tree, cls)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "#list of unique values for level 1\n",
    "level1_uniques=list(df_new.Level_1.unique())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "## Create and save models for level 2\n",
    "#Create and save model for level 2 looping trough all possibles signle values in level 1\n",
    "n_models_2=[]\n",
    "\n",
    "for i in level1_uniques:\n",
    "    x=list(class1[class1==i].index)\n",
    "    train_X.loc[train_X.index[x]]\n",
    "    #fit the model\n",
    "    tree.fit(train_X.loc[train_X.index[x]],class2[x])\n",
    "\n",
    "\n",
    "    #save level 2 classifier\n",
    "    with open(f\"level2_{i}.pk\", \"wb\") as cls:\n",
    "        pickle.dump(tree,cls)\n",
    "        n_models_2.append(i)\n",
    "    \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Create and save models for level 3\n",
    "#list of unique values for level 2\n",
    "level2_uniques=list(df_new.Level_2.unique())\n",
    "\n",
    "#Create and save model for level 3 looping trough all possibles signle values in level 2\n",
    "\n",
    "n_models_3=[]\n",
    "\n",
    "for j in level2_uniques:\n",
    "    x=list(class2[class2==j].index)\n",
    "    train_X.loc[train_X.index[x]]\n",
    "    #fit the model\n",
    "    tree.fit(train_X.loc[train_X.index[x]],class3[x])\n",
    "\n",
    "    #save level 3 classifier\n",
    "    with open(f\"level3_{j}.pk\", \"wb\") as cls:\n",
    "        pickle.dump(tree,cls)\n",
    "        n_models_3.append(i)\n",
    "        \n",
    "        \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Predict the test set (8 marks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Creating an empty Dataframe with column names only (depends on you how you do things)\n",
    "results = pd.DataFrame(columns=['Level1_Pred', 'Level2_Pred', 'Level3_Pred'])\n",
    "\n",
    "## Here we reload the saved models and use them to predict the levels\n",
    "# load model for level 1 (done for you)\n",
    "with open('level1.pk', 'rb') as nb:\n",
    "    model = pickle.load(nb)\n",
    "\n",
    "\n",
    "## loop through the test data, predict level 1, then based on that predict level 2\n",
    "## and based on level 2 predict level 3 (you need to load saved models accordingly)\n",
    "\n",
    "#Level 1 prediction\n",
    "l1_pred=model.predict(test_X)\n",
    "\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Leve 2 predictions\n",
    "l2_pred=[]\n",
    "for i in range(len(test_X)):\n",
    "\n",
    "    with open(f'level2_{l1_pred[i]}.pk', 'rb') as nb:\n",
    "        model = pickle.load(nb)\n",
    "\n",
    "    Level2_Pred=model.predict(test_X)\n",
    "    l2_pred.append(Level2_Pred[i])\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Level 3 predictions\n",
    "l3_pred=[]\n",
    "\n",
    "for i in range(len(test_X)):\n",
    "\n",
    "    with open(f'level3_{l2_pred[i]}.pk', 'rb') as nb:\n",
    "        model = pickle.load(nb)\n",
    "\n",
    "    Level3_Pred=model.predict(test_X)\n",
    "    l3_pred.append(Level3_Pred[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Level1_Pred</th>\n",
       "      <th>Level2_Pred</th>\n",
       "      <th>Level3_Pred</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2CEC27F1</td>\n",
       "      <td>BAE8A</td>\n",
       "      <td>2ABA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>90A8B052</td>\n",
       "      <td>C719A</td>\n",
       "      <td>A0E2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4513C920</td>\n",
       "      <td>E69F5</td>\n",
       "      <td>DDD5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>AAC8EE56</td>\n",
       "      <td>9B69F</td>\n",
       "      <td>80C4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>B092BA29</td>\n",
       "      <td>375FE</td>\n",
       "      <td>1F61</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2652</th>\n",
       "      <td>EFEF723B</td>\n",
       "      <td>02FA0</td>\n",
       "      <td>078B</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2653</th>\n",
       "      <td>96F95EEC</td>\n",
       "      <td>36080</td>\n",
       "      <td>C563</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2654</th>\n",
       "      <td>AAC8EE56</td>\n",
       "      <td>914A1</td>\n",
       "      <td>D97D</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2655</th>\n",
       "      <td>014303D1</td>\n",
       "      <td>7AED7</td>\n",
       "      <td>6539</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2656</th>\n",
       "      <td>2CEC27F1</td>\n",
       "      <td>ADAD6</td>\n",
       "      <td>98CF</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2657 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     Level1_Pred Level2_Pred Level3_Pred\n",
       "0       2CEC27F1       BAE8A        2ABA\n",
       "1       90A8B052       C719A        A0E2\n",
       "2       4513C920       E69F5        DDD5\n",
       "3       AAC8EE56       9B69F        80C4\n",
       "4       B092BA29       375FE        1F61\n",
       "...          ...         ...         ...\n",
       "2652    EFEF723B       02FA0        078B\n",
       "2653    96F95EEC       36080        C563\n",
       "2654    AAC8EE56       914A1        D97D\n",
       "2655    014303D1       7AED7        6539\n",
       "2656    2CEC27F1       ADAD6        98CF\n",
       "\n",
       "[2657 rows x 3 columns]"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results[\"Level1_Pred\"]=l1_pred\n",
    "results[\"Level2_Pred\"]=l2_pred\n",
    "results[\"Level3_Pred\"]=l3_pred\n",
    "\n",
    "#checking predictionds dataset\n",
    "results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Compute Accuracy on each level (4 marks)\n",
    "Now you have the predictions for each level (in the test data), and you also have the actual levels, you can compute the accurcay"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score, classification_report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8182160331200602\n"
     ]
    }
   ],
   "source": [
    "# Level 1 accuracy\n",
    "print(accuracy_score(test_y[['Level_1']], results[\"Level1_Pred\"]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7395558901016184\n"
     ]
    }
   ],
   "source": [
    "# Level 2 accuracy\n",
    "print(accuracy_score(test_y[['Level_2']], results[\"Level2_Pred\"]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7278885961610839\n"
     ]
    }
   ],
   "source": [
    "# Level 3 accuracy\n",
    "print(accuracy_score(test_y[['Level_3']], results[\"Level3_Pred\"]))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Well done!"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "ae417c91605ab94f1449220798012ca21034a4080ff7c1824cd7ad8522ba00f8"
  },
  "kernelspec": {
   "display_name": "Python 3.9.4 64-bit ('UOL': venv)",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
